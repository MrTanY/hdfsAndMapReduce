# 网络配置(配置静态ip)

`vim   /etc/sysconfig/network-scripts/ifcfg-eth0`    

`onboot=yes`  

## DNS1=114.114.114.114

`IPADDR=192.168.1.100`
`GATEWAY=192.168.1.1`
`NETMASK=255.255.255.0`

`重启 reboot`

# 安装ifconfig

`如果没有使用yum安装   yum install net-tools.x86_64`

# 安装rz插件

`yum install -y lrzsz` 

# 关闭防火墙

```
systemctl stop firewalld.service // 关闭防火墙

systemctl disable firewalld.service  //永久关闭

systemctl status firewalld.service //查看防火墙状态
```



# 虚拟机环境准备

## 修改主机名

`hostnamectl  set-hostname hadoop01 //设置主机名`

`service network restart //重启网络服务`

## 配置免密登录

ssh-keygen -t rsa    生成之后会在用户的根目录生成一个 “.ssh”的文件夹 

![image-20201203193535474](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20201203193535474.png)

`ssh-keygen -t rsa  //生成.ssh文件夹`

`cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys    //cat一下ssh`

 `ssh-copy-id 192.168.1.101  //复制到其他节点（所有节点都要执行）`

`scp 192.168.1.101:~/.ssh/authorized_keys ~/.ssh/   //复制到其他节点`

`chmod 700 ~/.ssh  //赋予权限`

`chmod 600 ~/.ssh/authorized_keys  //赋予权限`

## 时间同步配置

`yum -y install ntp ntpdate   //安装时间同步工具`

`ntpdate cn.pool.ntp.org  //设置时间同步`

`hwclock --systohc   //将系统时间写入硬件时间`

`timedatectl   //查看系统时间`

## java环境配置

`mkdir /app`

`tar -zxvf   jdk.tar.gz`

`vi /etc/profile.d/app.sh`

`export JAVA_HOME=/app/jdk1.8.0_181`

`export PATH=$PATH:$JAVA_HOME/bin`

`./etc/profile.d/app.sh //让配置在当前环境生效`

`java -version`

## 在/创建软件目录

`mkdir /opt/lagou/software    //软件安装包存放目录`

`mkdir /opt/lagou/servers   //软件安装目录`

`https://archive.apache.org/dist/hadoop/common/hadoop-29.2/  //hadoop下载地址`

# 集群规划

| 框架 | LOCA1              | LOCA2                        | LOCA3                       |
| ---- | :----------------- | ---------------------------- | --------------------------- |
| HDFS | nameNode、dataNode | dataNode                     | secondaryNameNode、dataNode |
| YARN | nodeManager        | resourceManager、nodeManager | nodeManager                 |

# 安装hadoop

```
vi /etc/profile  //配置环境变量
export HADOOP_HOME=/opt/lagou/servers/hadoop-2.9.2
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
. /etc/profile  //使当前环境生效
hadoop version //检查安装是否完成
```

# 集群配置

## hdfs集群配置

1. 指定hadoop的jdk路径（修改hadoop.env.sh）

   vi hadoop.env.sh   //找到java_home修改为本机jdk路径

2. 指定nameNode节点以及数据存储目录（修改core-site.xml）

   vi core-site.xml  //一定要配置在<configuration>标签内

   ```
   <!--指定hadoop运行时生产的文件存储目录-->
   <property>
   	<name>hadoop.tmp.dir</name>
   	<value>/opt/lagou/servers/hadoop-2.9.2/data/tmp</value>
   </property>
   <!--指定hdfs中namenode的地址-->
   <property>
   	<name>fs.defaultFS</name>
   	<value>hdfs://serv-1:9000</value>
   </property>
   ```

3. 指定secondaryNameNode节点（修改hdfs-site.xml）

   ```
   <!--指定hadoop辅助名称节点主机配置-->
   <property>
   	<name>dfs.namenode.secondary.http-address</name>
   	<value>hadoop03:50090</value>
   </property>
   <!--副本数量-->
   <property>
   	<name>dfs.replocation</name>
   	<value>3</value>
   </property>
   ```

4. 指定datanode从节点（修改etc/hadoop/slaves文件，每个节点配置占一行）

   配置各个节点的hostname

   ## MapReduce集群配置

1. 将JDK路径明确配置给MapReduce (修改mapred-env.sh)

   指定jdk路径

2. 指定MapReduce计算框架运行Yarn资源调度框架（修改mapred-site.xml)

   ```
   <!--指定mr运行在yarn上-->
   <property>
   	<name>mapreduce.framework.name</name>
   	<value>yarn</value>
   </property>
   ```

   ## yarn集群配置

   1. 将JDK路径明确配置给Yarn (修改yarn-env.sh)

      指定jdk路径

   2. 指定ResourceManager老大节点所在计算机节点(修改yarn-site.xml)

      ```
      <!--指定yarn的地址-->
      <property>
                      <name>yarn.resourcemanager.hostname</name>
                      <value>hadoop03</value>
              </property>
              <!--reducer获取数据的地址-->
               <property>
                      <name>yarn.nodemanager.aux-services</name>
                      <value>mapreduce_shuffle</value>
              </property>
      ```

      

   3. 指定NodeManager节点(会通过slaves文件内容确定)

**注意：**

修改hadoop所属用户组

chown -R root:root /opt/lagou/servers/hadoop-2.9.2

# 分发配置

yum install -y rsync

 rsync -rvl /opt/lagou/software/ root@hadoop02:/opt/lagou/software/   //复制到其他集群主机（单个）

basename   获取最后一级文件名称

dirname  获取最后一级文件的上级路径（相对路径会返回.）

whoami  获取当前用户信息

脚本拷贝多台（脚本统一放在/usr/local/bin）

```
#!/bin/bash
#需求：循环复制文件到集群所有节点的相同目录下
#使用方式：脚本+需要复制的文件名称
#脚本大致编写步骤
#1 获取传入脚本参数，参数个数
paramnum=$#

if((paramnum==0));
then
	echo no args;
exit;
fi 

#2 获取到文件名称
p1=$1

file_name=`basename $p1`
echo fname=${file_name}
#3 获取到文件的绝对路径，获取到文件的目录信息
dir_name=`cd -P $(dirname $p1);pwd`
#dir_name=`dirname $p1`
echo dirname=${dir_name}

#4 获取到当前用户信息
user=`whoami`
#5 执行rsync命令，循环执行
for((host=1;host<3;host++));
do
echo --------target hostname=hadoop0$host-------
rsync -rvl ${dir_name}/${file_name} ${user}@hadoop0${host}:${dir_name}
done

```

# 启动集群

**注意：如果集群是第一次启动，需要在namenode所在节点格式化namenode，非第一次不用执行格式化namenode操作**

## 单节点启动

```
hadoop namenode -format    //一定要在hadoop目录下执行    有如下提升success则表示格式化成功
```

![image-20201203223731371](D:\大数据学习资料\image-20201203223731371.png)

**hdfs单节点启动**

```
hadoop-daemon.sh   //单节点启动命令 停止吧start改为stop即可
hadoop-daemon.sh start namenode //启动hdfs可用jps查看是否启动成功
hadoop-daemon.sh start datanode //启动datanode（其余从节点分别启动）
```

**yarn单节点启动**

```
 yarn-daemon.sh start resourcemanager //主节点
 yarn-daemon.sh start nodemanager  //从节点
```

**hdfs群节点启动**（主节点在哪个节点上就在哪个节点启动）

```
start-dfs.sh  //关闭吧start换成stop
```

**yarn群节点启动**

```
start-yarn.sh
```

# 集群测试

**hdfs基本命令**

```
hdfs dfs -xxx      //基本上是hdfs  dfs   所要执行的命令
-put   -get  //上传下载
```

**执行mapreduce命令**

```
//使用jar的方式执行命令 跟上所要执行的命令  输入参数以及输出参数  输出参数一定不能提前创建
hadoop jar hadoop-mapreduce-examples-2.9.2.jar wordcount /wcinput /wcoutput
//可在ResourceManagerweb界面查看详细执行日志
```

## 配置历史服务器

```
vi mapred-site.xml
<!-- 历史服务器端地址 -->
<property>
 <name>mapreduce.jobhistory.address</name>
 <value>linux121:10020</value>
</property>
<!-- 历史服务器web端地址 -->
<property>
 <name>mapreduce.jobhistory.webapp.address</name>
 <value>linux121:19888</value>
</property>
//随后分发到其他节点

//在主节点启动历史日志服务
 mr-jobhistory-daemon.sh start historyserver
```

## 配置日志聚集

```
vi yarn-site.xml //开启后方便查看程序运行详情


<!-- ⽇志聚集功能使能 -->
<property>
<name>yarn.log-aggregation-enable</name>
<value>true</value>
</property>
<!-- ⽇志保留时间设置7天 -->
<property>
<name>yarn.log-aggregation.retain-seconds</name>
<value>604800</value>
</property>

//分发到其余节点

//先关闭主节点yarn
stop-yarn.sh
//重启jobhistory主节点
mr-jobhistory-daemon.sh





```

# HDFS客户端操作

## shell命令操作hdfs

```
基本语法
bin/hadoop fs 具体命令    以及   bin/hdfs  dfs  具体命令
```

